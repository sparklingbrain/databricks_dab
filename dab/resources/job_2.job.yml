# The main job for dab.
resources:
  jobs:
    job_2:
      name: job_2
      # Define Job Parameter
      parameters:
        - name: param_from_job_1
          default: ""

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      #email_notifications:
      #  on_failure:
      #    - your_email@example.com

      tasks: 
        - task_key: job_2_t2
          # job_cluster_key: job_cluster_1
          notebook_task: 
            notebook_path: ../notebooks/hello_2.ipynb
            base_parameters:      
             # Map this from_t1 from job_2 parameter value
              from_t1: "{{job.parameters.param_from_job_1}}"

      
        # - task_key: notebook_task
        #   # job_cluster_key: job_cluster_1
        #   notebook_task:
        #     # notebook_path: ../src/notebook.ipynb
        #     notebook_path: ${var.dab_notebook}
        #     base_parameters:
        #       notebook_param: "my_param_value"
              # limit_param: 1
            
        # - task_key: notebook_task_2
        #   # job_cluster_key: job_cluster_2
        #   notebook_task:
        #     # notebook_path: ../src/notebook.ipynb
        #     notebook_path: ${var.dab_notebook}

        # - task_key: notebook_task_3
        #   existing_dab_cluster: {var.existing_dab_cluster}            
        #   notebook_task:
        #     notebook_path: ${var.dab_notebook}

      queue:
        enabled: true
      performance_target: PERFORMANCE_OPTIMIZED
      # spark_conf:
      #   spark.speculation: true
      #   partitionDate: ${var.partitionDate}

      # job_clusters:
      #   - job_cluster_key: job_cluster_1
      #     new_cluster: ${var.dab_cluster_task_1}

      #   - job_cluster_key: job_cluster_2
      #     new_cluster: ${var.dab_cluster_task_2}

      #   - job_cluster_key: job_cluster_default
      #     new_cluster:
      #       spark_version: 15.4.x-scala2.12
      #       node_type_id: i3.xlarge
      #       data_security_mode: SINGLE_USER
      #       autoscale:
      #         min_workers: 1
      #         max_workers: 4
